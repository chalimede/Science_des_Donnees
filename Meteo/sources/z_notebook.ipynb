{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5f788b9",
   "metadata": {},
   "source": [
    "# Projet Météo.\n",
    "\n",
    "#### Copyright(C) 2024, Charles Theetten, <chalimede@proton.me>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9930007b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Charles\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "\n",
    "from    imblearn.metrics            import classification_report_imbalanced\n",
    "\n",
    "from    sklearn.ensemble            import StackingClassifier\n",
    "\n",
    "from    sklearn.model_selection     import cross_validate\n",
    "from    sklearn.model_selection     import train_test_split\n",
    "\n",
    "from    sklearn.preprocessing       import StandardScaler\n",
    "\n",
    "################################################################################\n",
    "\n",
    "import  matplotlib.pyplot           as plt\n",
    "\n",
    "from    plotly                      import graph_objs as go\n",
    "from    plotly.subplots             import make_subplots\n",
    "\n",
    "################################################################################\n",
    "\n",
    "import  joblib\n",
    "import  os\n",
    "import  numpy                       as np\n",
    "import  pandas                      as pd\n",
    "\n",
    "################################################################################\n",
    "\n",
    "from    nan_values                  import fillna_knn\n",
    "from    nan_values                  import fillna_rain_today\n",
    "\n",
    "################################################################################\n",
    "\n",
    "from    params_dl                   import IxHyperModel\n",
    "from    params_dl                   import IdxHyperModel\n",
    "from    params_dl                   import IddxHyperModel\n",
    "from    params_dl                   import IdOdxHyperModel\n",
    "from    params_dl                   import SrnnHyperModel\n",
    "from    params_dl                   import LSTMHyperModel\n",
    "from    params_dl                   import TestHyperModel\n",
    "\n",
    "################################################################################\n",
    "\n",
    "from    data                        import DataMeteo\n",
    "from    dl_models                   import DLModels\n",
    "from    ml_models                   import MlModels\n",
    "from    params_ml                   import space_lgb\n",
    "from    params_ml                   import space_lrc\n",
    "from    params_ml                   import space_knn\n",
    "from    params_ml                   import space_rfc\n",
    "from    results                     import Results\n",
    "\n",
    "from    transformers                import TrCleanCloud\n",
    "from    transformers                import TrCleanNaNRainTomorrow\n",
    "from    transformers                import TrCleanRowDate\n",
    "from    transformers                import TrCleanNaNRow\n",
    "from    transformers                import TrCleanRainTomorrow\n",
    "from    transformers                import TrClimaticClusters\n",
    "from    transformers                import TrDaysOfMonth\n",
    "from    transformers                import TrDaysOfYear\n",
    "from    transformers                import TrDiscretizeCloud\n",
    "from    transformers                import TrDiscretizeRain\n",
    "from    transformers                import TrDiscretizeWindDirection\n",
    "from    transformers                import TrGPS\n",
    "from    transformers                import TrSubsetNaN\n",
    "from    transformers                import TrZonesRain\n",
    "\n",
    "################################################################################\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\" , 1000)\n",
    "\n",
    "pd.set_option(\"mode.chained_assignment\", None)\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)\n",
    "\n",
    "################################################################################\n",
    "\n",
    "FILE = \"../csv/meteo_australia_2007_2017.csv\"\n",
    "\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a81e52",
   "metadata": {},
   "source": [
    "## Construction des jeux de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360360cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_clean_cloud          = TrCleanCloud()                                            # création du transformeur clean_cloud\n",
    "tr_clean_nan_raintom    = TrCleanNaNRainTomorrow()                                  # création du transformeur rain_clean_nan_tomorrow\n",
    "tr_clean_nan_row        = TrCleanNaNRow()                                           # création du transformeur clean_nan_row\n",
    "tr_clean_raintom        = TrCleanRainTomorrow()                                     # création du transformeur clean_raintom\n",
    "tr_clean_row_date       = TrCleanRowDate(2009)                                      # création du transformeur clean_row_date\n",
    "tr_climatic_clusters    = TrClimaticClusters()                                      # création du transformeur climatic_clusters\n",
    "tr_days_month           = TrDaysOfMonth()                                           # création du transformeur days_month\n",
    "tr_days_year            = TrDaysOfYear()                                            # création du transformeur days_year\n",
    "tr_discretize_cloud     = TrDiscretizeCloud()                                       # création du transformeur discrretize_cloud\n",
    "tr_discretize_rain      = TrDiscretizeRain()                                        # création du transformeur discretize_rain\n",
    "tr_discretize_wind_dir  = TrDiscretizeWindDirection()                               # création du transformeur discretize_wind_direction\n",
    "tr_gps                  = TrGPS()                                                   # création du transformeur gps\n",
    "tr_subset_nan           = TrSubsetNaN(49)                                           # création du transformeur subset_nan\n",
    "tr_zones_rain           = TrZonesRain()                                             # création du transformeur tr_zones_rain\n",
    "\n",
    "################################################################################\n",
    "\n",
    "data_meteo = DataMeteo(FILE)                                                        # instantiation de la classe DataMeteo\n",
    "\n",
    "################################################################################\n",
    "\n",
    "data_meteo.convert_to_datetime(\"Date\")                                              # conversion de la colonne date au format datetime\n",
    "\n",
    "################################################################################\n",
    "\n",
    "transformers    = [ (\"tr_clean_nan_row\",        tr_clean_nan_row),                  # suppression des lignes vides\n",
    "                    (\"tr_clean_row_date\",       tr_clean_row_date),                 # extraction des lignes >= 2009\n",
    "                    (\"tr_clean_nan_raintom\",    tr_clean_nan_raintom),              # suppression des variables cibles NaN\n",
    "                    (\"tr_subset_nan\",           tr_subset_nan),                     # extraction du sous-ensemble\n",
    "                    (\"tr_clean_cloud\",          tr_clean_cloud),                    # nettoyage de la variable cloud\n",
    "                    (\"tr_discretize_rain\",      tr_discretize_rain),                # discrétisation des variables de pluie\n",
    "                    (\"tr_discretize_wind_dir\",  tr_discretize_wind_dir) ]           # discrétisation des variables de vent\n",
    "\n",
    "data_meteo.build_dataset(transformers = transformers)                               # construction du nouveau dataset\n",
    "\n",
    "################################################################################\n",
    "\n",
    "data_meteo.change_type_columns([\"RainTomorrow\", \"RainToday\"], np.float64)           # conversion de type pour le remplacement des nan\n",
    "\n",
    "################################################################################\n",
    "\n",
    "data_meteo.data = fillna_rain_today(data_meteo.data)\n",
    "data_meteo.data = fillna_knn(data_meteo.data, 5, \"distance\", \"nan_euclidean\")       # remplissage des valeurs manquantes\n",
    "\n",
    "################################################################################\n",
    "\n",
    "transformers = [(\"tr_discretize_cloud\", tr_discretize_cloud),\n",
    "                (\"tr_clean_raintom\",    tr_clean_raintom) ]\n",
    "\n",
    "data_meteo.build_dataset(transformers = transformers)                               # Nettoyage final\n",
    "\n",
    "################################################################################\n",
    "\n",
    "data_meteo.display_info_data(10)                                                    # affichage des informations de base sur le nouveau dataset\n",
    "data_meteo.display_percentage_nan()                                                 # on s\"assure qu\"il n\"y ait pas de valeurs manquantes\n",
    "\n",
    "################################################################################\n",
    "\n",
    "data_meteo.data.to_csv(\"../csv/tests/df_49_knn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b42b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_49_knn = pd.read_csv(\"../csv/subsets/df_49_knn.csv\")\n",
    "\n",
    "cols = [\"MinTemp\", \"MaxTemp\", \"Rainfall\", \"Evaporation\", \"Sunshine\", \"WindGustSpeed\", \"WindSpeed9am\", \"WindSpeed3pm\",\n",
    "        \"Humidity9am\", \"Humidity3pm\", \"Pressure9am\", \"Pressure3pm\", \"Cloud9am\", \"Cloud3pm\", \"Temp9am\", \"Temp3pm\"]\n",
    "\n",
    "fig = make_subplots(rows = 1, cols = len(cols))\n",
    "\n",
    "for i, var in enumerate(cols):\n",
    "    fig.add_trace(go.Box(y    = df_49_knn[var],\n",
    "                         name = var),\n",
    "                         row  = 1, col = i + 1)\n",
    "\n",
    "fig.update_layout(title_text            = \"Distribution des variables sur l'ensemble KNN\",\n",
    "                  title_font_size       = 45,\n",
    "                  height = 600, width   = 2192,\n",
    "                  template              = \"plotly_dark\")\n",
    "fig.update_traces(jitter = .05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79e12f9",
   "metadata": {},
   "source": [
    "### Imputation KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bc413ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster        import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def extract_clean_data(data, city):\n",
    "    clean_data              = data[data[\"Location\"] == city]\n",
    "    clean_data              = clean_data.drop([\"Date\", \"Location\", \"RainTomorrow\"], axis = 1)\n",
    "    clean_data[\"RainToday\"] = clean_data[\"RainToday\"].astype(np.float64)\n",
    "    return clean_data\n",
    "\n",
    "def get_distorsions(data, nb_clusters):\n",
    "    distorsions = []\n",
    "\n",
    "    for n in range(1, nb_clusters):\n",
    "        cluster = KMeans(n_clusters = n, random_state = 123)\n",
    "        cluster.fit(data)\n",
    "        distorsions.append(sum(np.min(cdist(data, cluster.cluster_centers_, metric = \"euclidean\"), axis = 1)) / np.size(data, axis = 0))\n",
    "    return distorsions, cluster.cluster_centers_[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "213471cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_clean_cloud          = TrCleanCloud()                                                    # création du transformeur clean_cloud\n",
    "tr_clean_nan_raintom    = TrCleanNaNRainTomorrow()                                          # création du transformeur rain_clean_nan_tomorrow\n",
    "tr_clean_nan_row        = TrCleanNaNRow()                                                   # création du transformeur clean_nan_row\n",
    "tr_clean_raintom        = TrCleanRainTomorrow()                                             # création du transformeur clean_raintom\n",
    "tr_clean_row_date       = TrCleanRowDate(2009)                                              # création du transformeur clean_row_date\n",
    "tr_climatic_clusters    = TrClimaticClusters()                                              # création du transformeur climatic_clusters\n",
    "tr_days_month           = TrDaysOfMonth()                                                   # création du transformeur days_month\n",
    "tr_days_year            = TrDaysOfYear()                                                    # création du transformeur days_year\n",
    "tr_discretize_cloud     = TrDiscretizeCloud()                                               # création du transformeur discrretize_cloud\n",
    "tr_discretize_rain      = TrDiscretizeRain()                                                # création du transformeur discretize_rain\n",
    "tr_discretize_wind_dir  = TrDiscretizeWindDirection()                                       # création du transformeur discretize_wind_direction\n",
    "tr_gps                  = TrGPS()                                                           # création du transformeur gps\n",
    "tr_subset_nan           = TrSubsetNaN(49)                                                   # création du transformeur subset_nan\n",
    "tr_zones_rain           = TrZonesRain()                                                     # création du transformeur tr_zones_rain\n",
    "\n",
    "kmeans_data             = DataMeteo(FILE)\n",
    "\n",
    "kmeans_data.convert_to_datetime(\"Date\")\n",
    "\n",
    "transformers            = [ (\"tr_clean_nan_row\",        tr_clean_nan_row),                  # suppression des lignes vides\n",
    "                            (\"tr_clean_row_date\",       tr_clean_row_date),                 # extraction des lignes >= 2009\n",
    "                            (\"tr_clean_nan_raintom\",    tr_clean_nan_raintom),              # suppression des variables cibles NaN\n",
    "                            (\"tr_subset_nan\",           tr_subset_nan),                     # extraction du sous-ensemble\n",
    "                            (\"tr_clean_cloud\",          tr_clean_cloud),                    # nettoyage de la variable cloud\n",
    "                            (\"tr_discretize_rain\",      tr_discretize_rain),                # discrétisation des variables de pluie\n",
    "                            (\"tr_discretize_wind_dir\",  tr_discretize_wind_dir) ]           # discrétisation des variables de vent\n",
    "\n",
    "kmeans_data.build_dataset(transformers = transformers)\n",
    "\n",
    "clean_data              = kmeans_data.data.dropna()\n",
    "\n",
    "clean_data_sydney       = extract_clean_data(clean_data, \"Sydney\")\n",
    "clean_data_darwin       = extract_clean_data(clean_data, \"Darwin\")\n",
    "clean_data_alice        = extract_clean_data(clean_data, \"AliceSprings\")\n",
    "clean_data_perth        = extract_clean_data(clean_data, \"Perth\")\n",
    "clean_data_towns        = extract_clean_data(clean_data, \"Townsville\")\n",
    "clean_data_brisb        = extract_clean_data(clean_data, \"Brisbane\")\n",
    "clean_data_mildu        = extract_clean_data(clean_data, \"Mildura\")\n",
    "\n",
    "clean_data              = clean_data.drop([\"Date\", \"Location\", \"RainTomorrow\"], axis = 1)\n",
    "clean_data[\"RainToday\"] = clean_data[\"RainToday\"].astype(np.float64)\n",
    "\n",
    "distorsions, centroids  = get_distorsions(clean_data, 21)\n",
    "\n",
    "d_sydney, c_sydney      = get_distorsions(clean_data_sydney, 21)\n",
    "d_darwin, c_darwin      = get_distorsions(clean_data_darwin, 21)\n",
    "d_alice, c_alice        = get_distorsions(clean_data_alice, 21)\n",
    "d_perth, c_perth        = get_distorsions(clean_data_perth, 21)\n",
    "d_towns, c_towns        = get_distorsions(clean_data_towns, 21)\n",
    "d_brisb, c_brisb        = get_distorsions(clean_data_brisb, 21)\n",
    "d_mildu, c_mildu        = get_distorsions(clean_data_mildu, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bcfa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clusters = [i for i in range(1, 21)]\n",
    "\n",
    "fig = make_subplots(rows = 2, cols = 4, shared_yaxes = True)\n",
    "\n",
    "fig.add_trace(go.Scatter(x = nb_clusters, y = distorsions, mode = \"lines + markers\", xaxis=\"x1\"), row = 1, col = 1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x = nb_clusters, y = d_sydney, mode    = \"lines + markers\", xaxis=\"x2\"), row = 1, col = 2)\n",
    "\n",
    "fig.add_trace(go.Scatter(x = nb_clusters, y = d_darwin, mode    = \"lines + markers\", xaxis=\"x3\"), row = 1, col = 3)\n",
    "\n",
    "fig.add_trace(go.Scatter(x = nb_clusters, y = d_alice, mode     = \"lines + markers\", xaxis=\"x4\"), row = 1, col = 4)\n",
    "\n",
    "fig.add_trace(go.Scatter(x = nb_clusters, y = d_perth, mode     = \"lines + markers\", xaxis=\"x1\"), row = 2, col = 1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x = nb_clusters, y = d_towns, mode     = \"lines + markers\", xaxis=\"x2\"), row = 2, col = 2)\n",
    "\n",
    "fig.add_trace(go.Scatter(x = nb_clusters, y = d_brisb, mode     = \"lines + markers\", xaxis=\"x3\"), row = 2, col = 3)\n",
    "\n",
    "fig.add_trace(go.Scatter(x = nb_clusters, y = d_mildu, mode     = \"lines + markers\", xaxis=\"x4\"), row = 2, col = 4)\n",
    "\n",
    "fig.update_layout(width = 1920, height  = 1080,\n",
    "                  title_font_size       = 30,\n",
    "                  title_text            = \"Nombre de clusters optimal sur le jeu de données complet et par villes\",\n",
    "                  xaxis1                = dict(title = \"Australie\"),\n",
    "                  xaxis2                = dict(title = \"Sydney\"),\n",
    "                  xaxis3                = dict(title = \"Darwin\"),\n",
    "                  xaxis4                = dict(title = \"AliceSprings\"),\n",
    "                  xaxis5                = dict(title = \"Perth\"),\n",
    "                  xaxis6                = dict(title = \"Townsville\"),\n",
    "                  xaxis7                = dict(title = \"Brisbane\"),\n",
    "                  xaxis8                = dict(title = \"Mildura\"),\n",
    "                  )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfefc9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig         = make_subplots(rows = 1, cols = 4)\n",
    "\n",
    "fig.add_trace(go.Scatter(x = clean_data[\"Humidity9am\"].values[0:len(clean_data)], y = clean_data[\"Evaporation\"].values[0:len(clean_data)],\n",
    "                         mode = \"markers\", marker = dict(size = 2)), row = 1, col = 1)\n",
    "fig.add_trace(go.Scatter(x = centroids[:, 8], y = centroids[:, 3],\n",
    "                         mode = \"markers\", marker = dict(size = 12, color = \"RED\")), row = 1, col = 1)\n",
    "\n",
    "################################################################################\n",
    "\n",
    "fig.add_trace(go.Scatter(x = clean_data_sydney[\"Humidity9am\"].values[0:len(clean_data_sydney)], y = clean_data_sydney[\"Evaporation\"].values[0:len(clean_data_sydney)],\n",
    "                         mode = \"markers\", marker = dict(size = 3)), row = 1, col = 2)\n",
    "fig.add_trace(go.Scatter(x = c_sydney[:, 8], y = c_sydney[:, 3],\n",
    "                         mode = \"markers\", marker = dict(size = 12, color = \"SILVER\")), row = 1, col = 2)\n",
    "\n",
    "################################################################################\n",
    "\n",
    "fig.add_trace(go.Scatter(x = clean_data_darwin[\"Humidity9am\"].values[0:len(clean_data_darwin)], y = clean_data_darwin[\"Evaporation\"].values[0:len(clean_data_darwin)],\n",
    "                         mode = \"markers\", marker = dict(size = 3)), row = 1, col = 3)\n",
    "fig.add_trace(go.Scatter(x = c_darwin[:, 8], y = c_darwin[:, 3],\n",
    "                         mode = \"markers\", marker = dict(size = 12, color = \"Aqua\")), row = 1, col = 3)\n",
    "\n",
    "################################################################################\n",
    "\n",
    "fig.add_trace(go.Scatter(x = clean_data_alice[\"Humidity9am\"].values[0:len(clean_data_alice)], y = clean_data_alice[\"Evaporation\"].values[0:len(clean_data_alice)],\n",
    "                         mode = \"markers\", marker = dict(size = 3, color = \"#5DADE2\")), row = 1, col = 4)\n",
    "fig.add_trace(go.Scatter(x = c_alice[:, 8], y = c_alice[:, 3],\n",
    "                         mode = \"markers\", marker = dict(size = 12, color = \"LIME\")), row = 1, col = 4)\n",
    "\n",
    "\n",
    "fig.update_layout(width = 2192, height  = 720,\n",
    "                  title_font_size       = 40,\n",
    "                  title_text            = \"Clusters sur l'évaporation en fonction de l'humidité sur l'Australie et différentes villes\",\n",
    "                  template              = \"plotly_dark\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2604602",
   "metadata": {},
   "source": [
    "## Évaluation des différents modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c446b6f0",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dcea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE                = \"../csv/subsets/df_49_knn.csv\"\n",
    "MODEL               = \"LGB\"\n",
    "\n",
    "ml_meteo            = MlModels()\n",
    "results             = Results()\n",
    "\n",
    "ml_meteo.init_data(FILE, 2009, 2017)\n",
    "ml_meteo.split_data(\"RainTomorrow\", 0.20)\n",
    "ml_meteo.scale_data()\n",
    "\n",
    "print(ml_meteo.data.shape)\n",
    "\n",
    "clf, params         = ml_meteo.search_model(space_lgb, MODEL)\n",
    "eval                = ml_meteo.eval_model(clf, params)\n",
    "\n",
    "results.init_models(MODEL)\n",
    "results.register_ml(MODEL, clf, eval)\n",
    "results.write_ml_results(MODEL, f\"../results/results_{MODEL}_49.txt\")\n",
    "results.persist_ml_model(MODEL, \"../models/tests/\", \"_knn_49\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46efff5",
   "metadata": {},
   "source": [
    "#### Métriques sur le jeu de données complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5895453",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms  = [\"LRC\", \"KNN\", \"RFC\", \"LGB\"]\n",
    "\n",
    "fig         = go.Figure(data = [ go.Bar(name = \"Train score\",   x = algorithms, y = [0.868, 1.0, 0.936 , 0.961]),\n",
    "                                 go.Bar(name = \"Test score\",    x = algorithms, y = [0.888, 0.895, 0.938 , 0.944]),\n",
    "                                 go.Bar(name = \"Recall\",        x = algorithms, y = [0.76, 0.68, 0.81, 0.84]),\n",
    "                                 go.Bar(name = \"F1\",            x = algorithms, y = [0.75, 0.74, 0.85, 0.87])])\n",
    "\n",
    "fig.update_layout(width = 1920, height  = 1080,\n",
    "                  title_font_size       = 30,\n",
    "                  title_text            = \"Métriques des différents modèles de prédiction sur le jeu de données complet\",\n",
    "                  barmode               = \"group\",\n",
    "                  template              = \"plotly_dark\")\n",
    "\n",
    "fig.update_xaxes(tickfont = dict(size = 40))\n",
    "fig.update_yaxes(tickfont = dict(size = 20), tickmode = \"linear\", range = [0, 1], dtick = 0.05)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ee4183",
   "metadata": {},
   "source": [
    "#### Sous-ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd2f855",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL   = \"RFC\"\n",
    "scores  = []\n",
    "\n",
    "for file in os.listdir(\"../csv/subsets/\"):\n",
    "    ml_meteo    = MlModels()\n",
    "    results     = Results()\n",
    "\n",
    "    ml_meteo.init_data(\"../csv/subsets/\" + file, 2009, 2017)\n",
    "    ml_meteo.split_data(\"RainTomorrow\", 0.20)\n",
    "    ml_meteo.scale_data()\n",
    "    clf, params = ml_meteo.search_model(space_rfc, MODEL)\n",
    "    eval        = ml_meteo.eval_model(clf, params)\n",
    "\n",
    "    results.init_models(MODEL)\n",
    "    results.register_ml(MODEL, clf, eval)\n",
    "    scores.append(np.round(results.models[MODEL][\"tes\"], decimals = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b97f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7df2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_cities   = [ 1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 49 ]\n",
    "scores      = [ [ 0.841, 0.854, 0.851, 0.848, 0.855, 0.894, 0.913, 0.922, 0.930, 0.938, 0.944 ],\n",
    "                [ 0.821, 0.852, 0.842, 0.838, 0.841, 0.850, 0.858, 0.867, 0.878, 0.887, 0.894 ],\n",
    "                [ 0.829, 0.852, 0.851, 0.845, 0.849, 0.877, 0.899, 0.916, 0.924, 0.933, 0.939 ], ]\n",
    "algorithms  = [ \"LightGBM\", \"KNN\", \"Random Forests\" ]\n",
    "\n",
    "sum_nan     = [ 106,   153,   185,   196,   216,   374,   432,   617,  1096,\n",
    "                1162,  1261,  1370,  1529,  1575,  1812,  2125,  2505,  2740,\n",
    "                3490,  3518,  3600,  4038,  4392,  5787,  6083,  6467,  6563,\n",
    "                7075,  7184,  7991,  8361,  8368,  8847,  9997,  10105, 10255,\n",
    "                10859, 11218, 12791, 12840, 13195, 13314, 13524, 13537, 13648,\n",
    "                18854, 19564, 21801, 26528 ]\n",
    "ecdf        = []\n",
    "cum_sum     = 0\n",
    "\n",
    "for elem in sum_nan:\n",
    "    cum_sum = cum_sum + elem\n",
    "    ecdf.append(cum_sum)\n",
    "\n",
    "fig         = make_subplots(rows = 1, cols = 2, subplot_titles = [ \"Scores des tests en fonction du nombre de villes\",\n",
    "                                                                   \"Somme cumulée des valeurs manquantes en fonction du nombre de villes\" ])\n",
    "\n",
    "for i, algo in enumerate(algorithms):\n",
    "    fig.add_trace(go.Scatter(x      = nb_cities,\n",
    "                             y      = scores[i],\n",
    "                             mode   = \"lines + markers\",\n",
    "                             line   = dict(width = 3),\n",
    "                             name   = algo), row = 1, col = 1,)\n",
    "\n",
    "fig.add_trace(go.Scatter(x      = [i for i in range(1, 50)],\n",
    "                         y      = ecdf,\n",
    "                         mode   = \"lines + markers\",\n",
    "                         line   = dict(width = 1, color = \"orange\"),\n",
    "                         name   = \"ecdf\"), row = 1, col = 2)\n",
    "\n",
    "fig.update_layout(width = 1920, height  = 720,\n",
    "                  title_font_size       = 20,\n",
    "                  title_text            = \"Croissances comparées des scores de tests et des valeurs manquantes en fonction du nombre de villes triées par valeurs manquantes - KNN Imputation\",\n",
    "                  xaxis                 = dict(tickmode = \"linear\", tick0 = 0, dtick = 5),\n",
    "                  xaxis2                = dict(tickmode = \"linear\", tick0 = 0, dtick = 5),\n",
    "                  template              = \"plotly_dark\")\n",
    "\n",
    "fig.update_xaxes(title_font_size    = 20,\n",
    "                 tickfont           = dict(size = 20))\n",
    "fig.update_yaxes(tickfont = dict(size = 20))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca78fcb4",
   "metadata": {},
   "source": [
    "#### Sous-échantillonage et sur-échantillonage du modèle LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9722b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE                = \"../csv/subsets/df_49_knn.csv\"\n",
    "MODEL               = \"LGB\"\n",
    "\n",
    "ml_meteo            = MlModels()\n",
    "results             = Results()\n",
    "\n",
    "ml_meteo.init_data(FILE, 2009, 2017)\n",
    "ml_meteo.split_data(\"RainTomorrow\", 0.2)\n",
    "ml_meteo.scale_data()\n",
    "ml_meteo.under_sample_data(strategy = \"majority\", voting = \"hard\")\n",
    "\n",
    "print(ml_meteo.data.shape)\n",
    "\n",
    "clf, params = ml_meteo.search_model(space_lgb, MODEL)\n",
    "eval        = ml_meteo.eval_model(clf, params)\n",
    "\n",
    "results.init_models(MODEL)\n",
    "results.register_ml(MODEL, clf, eval)\n",
    "results.print_ml_results(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81e9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms  = [ \"LGB\" ]\n",
    "\n",
    "fig         = go.Figure(data = [ go.Bar(name = \"Test score\", x = algorithms, y = [ 0.944 ], marker_color = \"lime\"),\n",
    "                                 go.Bar(name = \"Hard score\", x = algorithms, y = [ 0.921 ], marker_color = \"#5DADE2\"),\n",
    "                                 go.Bar(name = \"Soft score\", x = algorithms, y = [ 0.753 ], marker_color = \"orange\")])\n",
    "\n",
    "fig.update_layout(width = 1080, height  = 720,\n",
    "                  title_font_size       = 20,\n",
    "                  title_text            = \"Sous-échantillonage de la classe majoritaire sur le jeu de données complet avec ClusterCentroids\",\n",
    "                  barmode               = \"group\",\n",
    "                  template              = \"plotly_dark\",\n",
    "                  bargroupgap = 0.1)\n",
    "\n",
    "fig.update_xaxes(tickfont = dict(size = 40))\n",
    "fig.update_yaxes(tickfont = dict(size = 20), tickmode = \"linear\", range = [0.5, 1], dtick = 0.05)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e130fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE                = \"../csv/subsets/df_49_knn.csv\"\n",
    "MODEL               = \"LGB\"\n",
    "\n",
    "ml_meteo            = MlModels()\n",
    "results             = Results()\n",
    "\n",
    "ml_meteo.init_data(FILE, 2009, 2017)\n",
    "ml_meteo.split_data(\"RainTomorrow\", 0.25)\n",
    "ml_meteo.scale_data()\n",
    "ml_meteo.over_sample_data(strategy = \"minority\")\n",
    "\n",
    "print(ml_meteo.data.shape)\n",
    "\n",
    "clf, params = ml_meteo.search_model(space_lgb, MODEL)\n",
    "eval        = ml_meteo.eval_model(clf, params)\n",
    "\n",
    "results.init_models(MODEL)\n",
    "results.register_ml(MODEL, clf, eval)\n",
    "results.print_ml_results(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b3342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms  = [ \"LGB\" ]\n",
    "\n",
    "fig         = go.Figure(data = [ go.Bar(name = \"Test score\", x = algorithms, y = [ 0.944 ], marker_color = \"lime\"),\n",
    "                                 go.Bar(name = \"Minority score\", x = algorithms, y = [ 0.938 ], marker_color = \"#5DADE2\"),\n",
    "                                 go.Bar(name = \"All score\", x = algorithms, y = [ 0.939 ], marker_color = \"orange\") ])\n",
    "\n",
    "fig.update_layout(width = 1080, height  = 720,\n",
    "                  title_font_size       = 20,\n",
    "                  title_text            = \"Sur-échantillonage de la classe majoritaire sur le jeu de données complet avec SMOTE\",\n",
    "                  barmode               = \"group\",\n",
    "                  template              = \"plotly_dark\",\n",
    "                  bargroupgap = 0.1)\n",
    "\n",
    "fig.update_xaxes(tickfont = dict(size = 40))\n",
    "fig.update_yaxes(tickfont = dict(size = 20), tickmode = \"linear\", range = [0.5, 1], dtick = 0.05)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8563fa42",
   "metadata": {},
   "source": [
    "#### Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e75843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE                    = \"../csv/subsets/df_49_knn.csv\"\n",
    "\n",
    "data                    = pd.read_csv(FILE)\n",
    "data[\"Date\"]            = pd.to_datetime(data[\"Date\"])\n",
    "data[\"RainTomorrow\"]    = data[\"RainTomorrow\"].astype(np.int8)\n",
    "data                    = data.sort_values(by = [\"Date\"])\n",
    "data                    = data.drop([\"Date\", \"Location\"], axis = 1)\n",
    "\n",
    "x                       = data.drop(\"RainTomorrow\", axis = 1)\n",
    "y                       = data[\"RainTomorrow\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, shuffle = False, random_state = 123)\n",
    "scaler                  = StandardScaler()\n",
    "x_train                 = scaler.fit_transform(x_train)\n",
    "x_test                  = scaler.transform(x_test)\n",
    "\n",
    "lrcc                    = joblib.load(\"../models/bests/LRC_knn_49.joblib\")\n",
    "knnc                    = joblib.load(\"../models/bests/KNN_knn_49.joblib\")\n",
    "rfcc                    = joblib.load(\"../models/bests/RFC_knn_49.joblib\")\n",
    "lgbc                    = joblib.load(\"../models/bests/LGB_knn_49.joblib\")\n",
    "\n",
    "sclf                    = StackingClassifier(estimators = [ (\"lrrc\", lrcc), (\"knnc\", knnc), (\"rfcc\", rfcc), (\"lgbc\", lgbc) ], final_estimator = lgbc)\n",
    "scores                  = cross_validate(sclf, x_train, y_train, scoring = [ \"accuracy\" ])\n",
    "\n",
    "sclf.fit(x_train, y_train)\n",
    "\n",
    "y_pred                  = sclf.predict(x_test)\n",
    "train_score             = sclf.score(x_train, y_train)\n",
    "test_score              = sclf.score(x_test, y_test)\n",
    "crosstab                = pd.crosstab(y_test, y_pred)\n",
    "report                  = classification_report_imbalanced(y_test, y_pred)\n",
    "\n",
    "print(f\"Train Score             : {train_score:.3f}\")\n",
    "print(f\"Test Score              : {test_score:.3f}\")\n",
    "print(f\"Confusion matrix        :\\n\\n{crosstab}\\n\\n\")\n",
    "print(f\"Classification report   :\\n{report}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c226963f",
   "metadata": {},
   "source": [
    "#### Importance des variables explicatives sur le modèle LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import plot_importance\n",
    "\n",
    "FILE                    = \"../csv/subsets/df_49_knn.csv\"\n",
    "\n",
    "data                    = pd.read_csv(FILE)\n",
    "data[\"Date\"]            = pd.to_datetime(data[\"Date\"])\n",
    "data[\"RainTomorrow\"]    = data[\"RainTomorrow\"].astype(np.int8)\n",
    "data                    = data.sort_values(by = [\"Date\"])\n",
    "data                    = data.drop([\"Date\", \"Location\"], axis = 1)\n",
    "\n",
    "x                       = data.drop(\"RainTomorrow\", axis = 1)\n",
    "y                       = data[\"RainTomorrow\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, shuffle = False, random_state = 123)\n",
    "scaler                  = StandardScaler()\n",
    "x_train                 = scaler.fit_transform(x_train)\n",
    "x_test                  = scaler.transform(x_test)\n",
    "\n",
    "lgbc                    = joblib.load(\"../models/bests/LGB_knn_49.joblib\")\n",
    "\n",
    "y_pred                  = lgbc.predict(x_test)\n",
    "train_score             = lgbc.score(x_train, y_train)\n",
    "test_score              = lgbc.score(x_test, y_test)\n",
    "crosstab                = pd.crosstab(y_test, y_pred)\n",
    "report                  = classification_report_imbalanced(y_test, y_pred)\n",
    "\n",
    "print(f\"Train Score             : {train_score:.3f}\")\n",
    "print(f\"Test Score              : {test_score:.3f}\")\n",
    "print(f\"Confusion matrix        :\\n\\n{crosstab}\\n\\n\")\n",
    "print(f\"Classification report   :\\n{report}\\n\")\n",
    "\n",
    "################################################################################\n",
    "\n",
    "ax                      = plot_importance(lgbc,\n",
    "                                          importance_type = \"gain\",\n",
    "                                          figsize=(16, 16),\n",
    "                                          title = \"LightGBM - Importance des variables explicatives [ Gain ]\")\n",
    "\n",
    "ax.set_yticklabels(x.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a18f524",
   "metadata": {},
   "source": [
    "#### Arbre d'exécution LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aac91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import plot_tree\n",
    "\n",
    "ax = plot_tree(lgbc, tree_index = 0, figsize = (4, 16), dpi = 1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e591b1c4",
   "metadata": {},
   "source": [
    "### Réseaux de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99551147",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE                = \"../csv/subsets/df_49_knn.csv\"\n",
    "PROJECT             = \"../models/deep_learning/trials/meteo_01\"\n",
    "MODEL               = \"Neural_Net_01\"\n",
    "\n",
    "dl_meteo            = DLModels()\n",
    "results             = Results()\n",
    "\n",
    "dl_meteo.init_data(FILE, 2009, 2017)\n",
    "dl_meteo.split_data(\"RainTomorrow\")\n",
    "dl_meteo.scale_data()\n",
    "\n",
    "model               = IxHyperModel()\n",
    "\n",
    "clf, best_params    = dl_meteo.search_model(model   = model,\n",
    "                                            epochs  = 10,\n",
    "                                            project = PROJECT)\n",
    "\n",
    "eval                = dl_meteo.eval_dense_model(model         = clf,\n",
    "                                                best_params   = best_params,\n",
    "                                                epochs        = 100,\n",
    "                                                split         = 0.2)\n",
    "\n",
    "results.init_models(MODEL)\n",
    "results.register_dl(MODEL, clf, eval)\n",
    "results.write_dl_results(MODEL, f\"../results/deep_learning/results_{MODEL}_49.txt\")\n",
    "results.persist_dl_model(clf, MODEL, \"../models/deep_learning/dense_neural_networks/\", \"_knn_49\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd93764",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE                = \"../csv/subsets/df_49_knn.csv\"\n",
    "PROJECT             = \"../models/deep_learning/trials/meteo_02\"\n",
    "MODEL               = \"Neural_Net_02\"\n",
    "\n",
    "dl_meteo            = DLModels()\n",
    "results             = Results()\n",
    "\n",
    "dl_meteo.init_data(FILE, 2009, 2017)\n",
    "dl_meteo.split_data(\"RainTomorrow\")\n",
    "dl_meteo.scale_data()\n",
    "\n",
    "print(dl_meteo.data.shape)\n",
    "\n",
    "model               = IdxHyperModel()\n",
    "\n",
    "clf, best_params    = dl_meteo.search_model(model   = model,\n",
    "                                            epochs  = 10,\n",
    "                                            project = PROJECT)\n",
    "\n",
    "eval                = dl_meteo.eval_dense_model(model         = clf,\n",
    "                                          best_params   = best_params,\n",
    "                                          epochs        = 100,\n",
    "                                          split         = 0.2)\n",
    "\n",
    "results.init_models(MODEL)\n",
    "results.register_dl(MODEL, clf, eval)\n",
    "results.write_dl_results(MODEL, f\"../results/deep_learning/results_{MODEL}_49.txt\")\n",
    "results.persist_dl_model(clf, MODEL, \"../models/deep_learning/dense_neural_networks/\", \"_knn_49\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c39b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE                = \"../csv/subsets/df_49_knn.csv\"\n",
    "PROJECT             = \"../models/deep_learning/trials/meteo_03\"\n",
    "MODEL               = \"Neural_Net_03\"\n",
    "\n",
    "dl_meteo            = DLModels()\n",
    "results             = Results()\n",
    "\n",
    "dl_meteo.init_data(FILE, 2009, 2017)\n",
    "dl_meteo.split_data(\"RainTomorrow\")\n",
    "dl_meteo.scale_data()\n",
    "\n",
    "print(dl_meteo.data.shape)\n",
    "\n",
    "model               = IddxHyperModel()\n",
    "\n",
    "clf, best_params    = dl_meteo.search_model(model   = model,\n",
    "                                            epochs  = 10,\n",
    "                                            project = PROJECT)\n",
    "\n",
    "eval                = dl_meteo.eval_dense_model(model         = clf,\n",
    "                                                best_params   = best_params,\n",
    "                                                epochs        = 100,\n",
    "                                                split         = 0.2)\n",
    "\n",
    "results.init_models(MODEL)\n",
    "results.register_dl(MODEL, clf, eval)\n",
    "results.write_dl_results(MODEL, f\"../results/deep_learning/results_{MODEL}_49.txt\")\n",
    "results.persist_dl_model(clf, MODEL, \"../models/deep_learning/dense_neural_networks/\", \"_knn_49\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45175f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE                = \"../csv/subsets/df_49_knn.csv\"\n",
    "PROJECT             = \"../models/deep_learning/trials/meteo_04\"\n",
    "MODEL               = \"Neural_Net_04\"\n",
    "\n",
    "dl_meteo            = DLModels()\n",
    "results             = Results()\n",
    "\n",
    "dl_meteo.init_data(FILE, 2009, 2017)\n",
    "dl_meteo.split_data(\"RainTomorrow\")\n",
    "dl_meteo.scale_data()\n",
    "\n",
    "print(dl_meteo.data.shape)\n",
    "\n",
    "model               = IdOdxHyperModel()\n",
    "\n",
    "clf, best_params    = dl_meteo.search_model(model   = model,\n",
    "                                            epochs  = 50,\n",
    "                                            project = PROJECT)\n",
    "\n",
    "eval                = dl_meteo.eval_dense_model(model         = clf,\n",
    "                                                best_params   = best_params,\n",
    "                                                epochs        = 100,\n",
    "                                                split         = 0.2)\n",
    "\n",
    "results.init_models(MODEL)\n",
    "results.register_dl(MODEL, clf, eval)\n",
    "results.write_dl_results(MODEL, f\"../results/deep_learning/results_{MODEL}_49.txt\")\n",
    "results.persist_dl_model(clf, MODEL, \"../models/deep_learning/dense_neural_networks/\", \"_knn_49\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991aa4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE                = \"../csv/subsets/df_49_knn.csv\"\n",
    "PROJECT             = \"../models/deep_learning/trials/meteo_05\"\n",
    "MODEL               = \"Neural_Net_05\"\n",
    "\n",
    "dl_meteo            = DLModels()\n",
    "results             = Results()\n",
    "\n",
    "dl_meteo.init_data(FILE, 2009, 2017)\n",
    "dl_meteo.split_data(\"RainTomorrow\")\n",
    "dl_meteo.scale_data()\n",
    "\n",
    "print(dl_meteo.data.shape)\n",
    "\n",
    "dl_meteo.x_train    = np.reshape(dl_meteo.x_train, (dl_meteo.x_train.shape[0], dl_meteo.x_train.shape[1], 1))\n",
    "dl_meteo.x_test     = np.reshape(dl_meteo.x_test, (dl_meteo.x_test.shape[0], dl_meteo.x_test.shape[1], 1))\n",
    "\n",
    "model               = SrnnHyperModel()\n",
    "\n",
    "clf, best_params    = dl_meteo.search_model(model   = model,\n",
    "                                            epochs  = 50,\n",
    "                                            project = PROJECT)\n",
    "\n",
    "eval                = dl_meteo.eval_recurrent_model(model         = clf,\n",
    "                                                    best_params   = best_params,\n",
    "                                                    epochs        = 100,\n",
    "                                                    split         = 0.2)\n",
    "\n",
    "results.init_models(MODEL)\n",
    "results.register_dl(MODEL, clf, eval)\n",
    "results.write_dl_results(MODEL, f\"../results/deep_learning/results_{MODEL}_49.txt\")\n",
    "results.persist_dl_model(clf, MODEL, \"../models/deep_learning/dense_neural_networks/\", \"_knn_49\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256994b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE                = \"../csv/subsets/df_49_knn.csv\"\n",
    "PROJECT             = \"../models/deep_learning/trials/test\"\n",
    "MODEL               = \"Neural_Net_Test\"\n",
    "\n",
    "dl_meteo            = DLModels()\n",
    "results             = Results()\n",
    "\n",
    "dl_meteo.init_data(FILE, 2009, 2017)\n",
    "dl_meteo.split_data(\"RainTomorrow\")\n",
    "dl_meteo.scale_data()\n",
    "\n",
    "print(dl_meteo.data.shape)\n",
    "\n",
    "dl_meteo.x_train    = np.reshape(dl_meteo.x_train, (dl_meteo.x_train.shape[0], dl_meteo.x_train.shape[1], 1))\n",
    "dl_meteo.x_test     = np.reshape(dl_meteo.x_test, (dl_meteo.x_test.shape[0], dl_meteo.x_test.shape[1], 1))\n",
    "\n",
    "model               = LSTMHyperModel()\n",
    "\n",
    "clf, best_params    = dl_meteo.search_model(model   = model,\n",
    "                                            epochs  = 50,\n",
    "                                            project = PROJECT)\n",
    "\n",
    "eval                = dl_meteo.eval_model(model         = clf,\n",
    "                                          best_params   = best_params,\n",
    "                                          epochs        = 100,\n",
    "                                          split         = 0.2)\n",
    "\n",
    "results.init_models(MODEL)\n",
    "results.register_dl(MODEL, clf, eval)\n",
    "results.write_dl_results(MODEL, f\"../results/deep_learning/results_{MODEL}_49.txt\")\n",
    "results.persist_dl_model(clf, MODEL, \"../models/deep_learning/dense_neural_networks/\", \"_knn_49\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
